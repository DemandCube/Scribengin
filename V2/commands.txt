#Requirements#

config
  change-config (change config on the fly)
status
  up time (how long cluster has been up, and each individual node)
  container info (memory, cpu usage, etc)
upload [jar]
  upload an arbitrary dataflow
  upload an arbitrary job to run in the cluster
scribengin
  restart
registry
  info on specific dataflows, machines
  info on history, etc
dataflow
  dataflow [name of flow] info
  dataflow [name of flow] stop
  dataflow [name of flow] pause
  dataflow [name of flow] resume




Available commands:
==================
dataflow:
  commands for interacting with dataflows

  * info
    display more info about dataflows

        Option      Description                 Default Value
        --------------------------------------------------------
        --running   The running dataflow name

  * submit
    submit a dataflow

        Option         Description                                       Default Value
        ---------------------------------------------------------------------------------
        --descriptor   The dataflow descriptor path in the json format
  * stop
    This command should stop a running dataflow

    --dataflow-id:  The dataflow id 

    TODO: Implement this command. The steps to stop a dataflow:

    1. Find out the the dataflow in the registry by the dataflow-id
    2. Place or send an stop event in the dataflow events node
    3. The dataflow master should listen to the dataflow event and pickup the stop event.
    4. The dataflow master should find out all the dataflow worker, place a stop command in each dataflow worker
    5. The dataflow worker should catch the command and stop all the running dataflow task properly
    6. The dataflow master should wait for all the dataflow worker exit properly. 
    7. The dataflow master should make the running dataflow status as failed and terminated
    8. The dataflow master should shutdown the backup dataflow master.
    9. The dataflow master shutdown itself
    10. The scribengin master should detect a dataflow terminated and move it to the history

    Need to figure out a way to log those steps in the registry since the dataflow master can fail at the middle. 
    The backup master should continue the process according to the log in the registry. Many operation should use 
    the registry transaction as well to make sure that each step is reliablely processed

    Actually, we need to make a framework that allow us to split an action into many steps. Those step should be store in the registry.
    Each step should be reliably executed and mark as waiting, finished status... The master should be responsible to coordinate and 
    schedule those steps. If the master crashed, the backup master suppose to be able to resume the steps.

  * pause
    This command should pause a running dataflow

    --dataflow-id:  The dataflow id 

    TODO: See the stop subcommand to have an idea what need to be done

  * resume
    This command should resume a pause dataflow

    --dataflow-id:  The dataflow id 

    TODO: See the stop subcommand to have an idea what need to be done
  


dataflow-test:
  a sample dataflow

  * hdfs
    creates the sample dataflow

  * hdfs-kafka
    creates the sample dataflow

  * kafka
    creates the sample dataflow

  * kafka-hdfs
    creates the sample dataflow

  * kafka-s3
    creates the sample dataflow
    
  TODO: figure out a way to print out the description and parameters for this command


help:
  displays valid commands and their arguments.



registry:
  Commands for querying the registry

  * dump
    dump contents of the registry path

        Option   Description                                    Default Value
        ------------------------------------------------------------------------
        --path   The path to dump, the default path is root /   /



scribengin:
  commands for interacting with the scribengin cluster.

  * info
    get info about the scribengin cluster

  * master
    commands for managing the Scribengin master.

        Option       Description               Default Value
        -------------------------------------------------------
        --shutdown   Shutdown current master   false

  * shutdown
    shutdown a scribengin cluster.

  * start
    start a scribenging cluster



vm:
  Commands related to VM instances.

  * info
    print out info about running and history vms

  * shutdown
    This command will shutdown all the running vm, and then shutdown the
    vm-master. This is a dangerous operation - the cluster will not
    shutdown properly unless you have already shutdown all running VMs
    properly

  * start
    This will start the first vm, vm-master. The vm-master will be responsible
    for managing, starting, and stopping other VMs upon request


